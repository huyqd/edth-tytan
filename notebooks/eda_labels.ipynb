{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e80f5b8",
   "metadata": {},
   "source": [
    "# Flight1 Data Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook provides a comprehensive overview of the Flight1 dataset, including:\n",
    "- Data structure and types\n",
    "- Timestamp analysis and sampling frequency\n",
    "- Sensor data distributions (quaternions, angular velocity, acceleration)\n",
    "- Data quality checks (nulls, gaps, outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f419d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3533e5",
   "metadata": {},
   "source": [
    "## 1. Load Data and Basic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels data (sensor readings aligned with frames)\n",
    "labels_df = pd.read_csv(\"/Users/h33662/Projects/self/edth/data/labels/Flight1.csv\")\n",
    "\n",
    "# Load the raw logs data\n",
    "logs_df = pd.read_csv(\"/Users/h33662/Projects/self/edth/data/raw/logs/Flight1.csv\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LABELS DATASET (sensor data aligned with video frames)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {labels_df.shape[0]:,} rows × {labels_df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(labels_df.columns)}\")\n",
    "print(f\"\\nData types:\\n{labels_df.dtypes}\")\n",
    "print(f\"\\nMemory usage: {labels_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOGS DATASET (raw flight logs)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {logs_df.shape[0]:,} rows × {logs_df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(logs_df.columns)}\")\n",
    "print(f\"\\nData types:\\n{logs_df.dtypes}\")\n",
    "print(f\"\\nMemory usage: {logs_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first and last few rows\n",
    "print(\"First 5 rows of labels:\")\n",
    "display(labels_df.head())\n",
    "\n",
    "print(\"\\nLast 5 rows of labels:\")\n",
    "display(labels_df.tail())\n",
    "\n",
    "print(\"\\nFirst 5 rows of logs:\")\n",
    "display(logs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d3961",
   "metadata": {},
   "source": [
    "## 2. Timestamp Analysis & Conversion\n",
    "\n",
    "The `timestamp` column contains microsecond values. We'll convert these to readable formats and analyze sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07615a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp from microseconds to seconds\n",
    "labels_df[\"timestamp_s\"] = labels_df[\"timestamp\"] / 1e6\n",
    "labels_df[\"elapsed_s\"] = labels_df[\"timestamp_s\"] - labels_df[\"timestamp_s\"].iloc[0]\n",
    "\n",
    "# Compute time differences (sampling intervals)\n",
    "labels_df[\"dt_us\"] = labels_df[\"timestamp\"].diff()  # microseconds\n",
    "labels_df[\"dt_s\"] = labels_df[\"dt_us\"] / 1e6  # seconds\n",
    "\n",
    "# Summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"TIMESTAMP STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    f\"Total duration: {labels_df['elapsed_s'].iloc[-1]:.2f} seconds ({labels_df['elapsed_s'].iloc[-1] / 60:.2f} minutes)\"\n",
    ")\n",
    "print(f\"Number of samples: {len(labels_df):,}\")\n",
    "print(f\"\\nTimestamp range (microseconds):\")\n",
    "print(f\"  Start: {labels_df['timestamp'].iloc[0]:,}\")\n",
    "print(f\"  End:   {labels_df['timestamp'].iloc[-1]:,}\")\n",
    "print(f\"\\nSampling interval (dt) statistics:\")\n",
    "print(labels_df[\"dt_s\"].describe())\n",
    "print(f\"\\nMean sampling rate: {1 / labels_df['dt_s'].mean():.2f} Hz\")\n",
    "print(f\"Median sampling rate: {1 / labels_df['dt_s'].median():.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3714d",
   "metadata": {},
   "source": [
    "## 3. Sampling Frequency Distribution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sampling interval distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Histogram of sampling intervals\n",
    "ax = axes[0, 0]\n",
    "labels_df[\"dt_s\"].dropna().hist(bins=100, ax=ax, edgecolor=\"black\", alpha=0.7)\n",
    "ax.set_xlabel(\"Sampling Interval (seconds)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Distribution of Sampling Intervals\")\n",
    "ax.axvline(\n",
    "    labels_df[\"dt_s\"].median(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {labels_df['dt_s'].median():.6f}s\",\n",
    ")\n",
    "ax.axvline(\n",
    "    labels_df[\"dt_s\"].mean(),\n",
    "    color=\"orange\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {labels_df['dt_s'].mean():.6f}s\",\n",
    ")\n",
    "ax.legend()\n",
    "\n",
    "# 2. Sampling rate over time\n",
    "ax = axes[0, 1]\n",
    "# Compute rolling sampling rate (Hz) in windows\n",
    "window_size = 100\n",
    "labels_df[\"sampling_rate_hz\"] = 1 / labels_df[\"dt_s\"]\n",
    "rolling_rate = (\n",
    "    labels_df[\"sampling_rate_hz\"].rolling(window=window_size, center=True).mean()\n",
    ")\n",
    "ax.plot(labels_df[\"elapsed_s\"], rolling_rate, alpha=0.7, linewidth=0.8)\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Sampling Rate (Hz)\")\n",
    "ax.set_title(f\"Sampling Rate Over Time (rolling window={window_size})\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Cumulative sample count over time\n",
    "ax = axes[1, 0]\n",
    "ax.plot(labels_df[\"elapsed_s\"], np.arange(len(labels_df)), linewidth=1.5)\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Cumulative Sample Count\")\n",
    "ax.set_title(\"Cumulative Samples Over Time\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Identify and visualize time gaps\n",
    "ax = axes[1, 1]\n",
    "# Flag large gaps (e.g., > 2x median interval)\n",
    "median_dt = labels_df[\"dt_s\"].median()\n",
    "threshold = 2 * median_dt\n",
    "gaps = labels_df[labels_df[\"dt_s\"] > threshold].copy()\n",
    "ax.scatter(\n",
    "    gaps[\"elapsed_s\"],\n",
    "    gaps[\"dt_s\"],\n",
    "    color=\"red\",\n",
    "    s=50,\n",
    "    alpha=0.7,\n",
    "    label=f\"Gaps (>{threshold:.6f}s)\",\n",
    ")\n",
    "ax.scatter(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"dt_s\"], alpha=0.3, s=1, label=\"All intervals\"\n",
    ")\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Sampling Interval (seconds)\")\n",
    "ax.set_title(f\"Time Gaps Detection (threshold={threshold:.6f}s)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDetected {len(gaps)} time gaps (intervals > {threshold:.6f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758beda4",
   "metadata": {},
   "source": [
    "## 4. Sensor Data Distributions\n",
    "\n",
    "Analyze the distributions of quaternions (orientation), angular velocities, and accelerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ace673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for sensor columns\n",
    "sensor_cols = [\n",
    "    \"qw\",\n",
    "    \"qx\",\n",
    "    \"qy\",\n",
    "    \"qz\",\n",
    "    \"wx_radDs\",\n",
    "    \"wy_radDs\",\n",
    "    \"wz_radDs\",\n",
    "    \"ax_mDs2\",\n",
    "    \"ay_mDs2\",\n",
    "    \"az_mDs2\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SENSOR DATA STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(labels_df[sensor_cols].describe())\n",
    "\n",
    "# Check quaternion normalization (should be ~1.0 if normalized)\n",
    "labels_df[\"quat_norm\"] = np.sqrt(\n",
    "    labels_df[\"qw\"] ** 2\n",
    "    + labels_df[\"qx\"] ** 2\n",
    "    + labels_df[\"qy\"] ** 2\n",
    "    + labels_df[\"qz\"] ** 2\n",
    ")\n",
    "print(f\"\\nQuaternion norm statistics (should be ≈1.0 if normalized):\")\n",
    "print(labels_df[\"quat_norm\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor data distributions\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 12))\n",
    "\n",
    "# Quaternions\n",
    "for i, col in enumerate([\"qw\", \"qx\", \"qy\", \"qz\"]):\n",
    "    ax = axes[0, i]\n",
    "    labels_df[col].hist(bins=50, ax=ax, edgecolor=\"black\", alpha=0.7)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Angular velocities\n",
    "for i, col in enumerate([\"wx_radDs\", \"wy_radDs\", \"wz_radDs\"]):\n",
    "    ax = axes[1, i]\n",
    "    labels_df[col].hist(bins=50, ax=ax, edgecolor=\"black\", alpha=0.7, color=\"orange\")\n",
    "    ax.set_xlabel(f\"{col} (rad/s)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Quaternion norm\n",
    "ax = axes[1, 3]\n",
    "labels_df[\"quat_norm\"].hist(bins=50, ax=ax, edgecolor=\"black\", alpha=0.7, color=\"green\")\n",
    "ax.set_xlabel(\"Quaternion Norm\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Distribution of Quaternion Norm\")\n",
    "ax.axvline(1.0, color=\"red\", linestyle=\"--\", label=\"Expected: 1.0\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accelerations\n",
    "for i, col in enumerate([\"ax_mDs2\", \"ay_mDs2\", \"az_mDs2\"]):\n",
    "    ax = axes[2, i]\n",
    "    labels_df[col].hist(bins=50, ax=ax, edgecolor=\"black\", alpha=0.7, color=\"red\")\n",
    "    ax.set_xlabel(f\"{col} (m/s²)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# System time\n",
    "ax = axes[2, 3]\n",
    "labels_df[\"system_time_s\"].hist(\n",
    "    bins=50, ax=ax, edgecolor=\"black\", alpha=0.7, color=\"purple\"\n",
    ")\n",
    "ax.set_xlabel(\"System Time (s)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Distribution of system_time_s\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9d538",
   "metadata": {},
   "source": [
    "## 5. Time Series Visualization of Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc587c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor data over time\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# Quaternions over time\n",
    "ax = axes[0]\n",
    "ax.plot(labels_df[\"elapsed_s\"], labels_df[\"qw\"], label=\"qw\", alpha=0.7, linewidth=0.8)\n",
    "ax.plot(labels_df[\"elapsed_s\"], labels_df[\"qx\"], label=\"qx\", alpha=0.7, linewidth=0.8)\n",
    "ax.plot(labels_df[\"elapsed_s\"], labels_df[\"qy\"], label=\"qy\", alpha=0.7, linewidth=0.8)\n",
    "ax.plot(labels_df[\"elapsed_s\"], labels_df[\"qz\"], label=\"qz\", alpha=0.7, linewidth=0.8)\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Quaternion Components\")\n",
    "ax.set_title(\"Orientation (Quaternions) Over Time\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Angular velocities over time\n",
    "ax = axes[1]\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"wx_radDs\"], label=\"ωx\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"wy_radDs\"], label=\"ωy\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"wz_radDs\"], label=\"ωz\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Angular Velocity (rad/s)\")\n",
    "ax.set_title(\"Angular Velocities Over Time\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accelerations over time\n",
    "ax = axes[2]\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"ax_mDs2\"], label=\"ax\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"ay_mDs2\"], label=\"ay\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.plot(\n",
    "    labels_df[\"elapsed_s\"], labels_df[\"az_mDs2\"], label=\"az\", alpha=0.7, linewidth=0.8\n",
    ")\n",
    "ax.set_xlabel(\"Elapsed Time (seconds)\")\n",
    "ax.set_ylabel(\"Acceleration (m/s²)\")\n",
    "ax.set_title(\"Accelerations Over Time\")\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2e27b",
   "metadata": {},
   "source": [
    "## 6. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a429f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "missing = labels_df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"✓ No missing values found\")\n",
    "\n",
    "# Check for duplicate timestamps\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DUPLICATE TIMESTAMPS CHECK\")\n",
    "print(\"=\" * 60)\n",
    "duplicates = labels_df[\"timestamp\"].duplicated().sum()\n",
    "print(\n",
    "    f\"Found {duplicates} duplicate timestamps\"\n",
    "    if duplicates > 0\n",
    "    else \"✓ No duplicate timestamps\"\n",
    ")\n",
    "\n",
    "# Check for monotonicity (timestamps should always increase)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TIMESTAMP MONOTONICITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "non_monotonic = (\n",
    "    labels_df[\"timestamp\"].diff() <= 0\n",
    ").sum() - 1  # -1 to exclude first NaN\n",
    "print(\n",
    "    f\"⚠ Found {non_monotonic} non-monotonic timestamp transitions\"\n",
    "    if non_monotonic > 0\n",
    "    else \"✓ Timestamps are strictly monotonic (always increasing)\"\n",
    ")\n",
    "\n",
    "# Outlier detection using IQR method for sensor data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER DETECTION (IQR method, threshold=3.0)\")\n",
    "print(\"=\" * 60)\n",
    "outlier_summary = {}\n",
    "for col in sensor_cols:\n",
    "    Q1 = labels_df[col].quantile(0.25)\n",
    "    Q3 = labels_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 3.0 * IQR\n",
    "    upper_bound = Q3 + 3.0 * IQR\n",
    "    outliers = ((labels_df[col] < lower_bound) | (labels_df[col] > upper_bound)).sum()\n",
    "    outlier_summary[col] = outliers\n",
    "    if outliers > 0:\n",
    "        print(f\"  {col}: {outliers} outliers ({100 * outliers / len(labels_df):.2f}%)\")\n",
    "\n",
    "if sum(outlier_summary.values()) == 0:\n",
    "    print(\"✓ No significant outliers detected in sensor data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b6e33",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for sensor data\n",
    "corr_matrix = labels_df[sensor_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Correlation Matrix of Sensor Data\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify strong correlations (|r| > 0.7, excluding diagonal)\n",
    "print(\"=\" * 60)\n",
    "print(\"STRONG CORRELATIONS (|r| > 0.7)\")\n",
    "print(\"=\" * 60)\n",
    "strong_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            strong_corr.append(\n",
    "                (corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j])\n",
    "            )\n",
    "\n",
    "if strong_corr:\n",
    "    for col1, col2, r in sorted(strong_corr, key=lambda x: abs(x[2]), reverse=True):\n",
    "        print(f\"  {col1} ↔ {col2}: r = {r:.3f}\")\n",
    "else:\n",
    "    print(\"✓ No strong correlations found (all |r| ≤ 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431c85b",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc146fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary\n",
    "summary = {\n",
    "    \"Metric\": [\n",
    "        \"Total Samples\",\n",
    "        \"Total Duration (s)\",\n",
    "        \"Total Duration (min)\",\n",
    "        \"Mean Sampling Rate (Hz)\",\n",
    "        \"Median Sampling Rate (Hz)\",\n",
    "        \"Timestamp Range (µs)\",\n",
    "        \"Number of Time Gaps (>2×median)\",\n",
    "        \"Missing Values\",\n",
    "        \"Duplicate Timestamps\",\n",
    "        \"Non-monotonic Transitions\",\n",
    "        \"Quaternion Norm Mean\",\n",
    "        \"Quaternion Norm Std\",\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{len(labels_df):,}\",\n",
    "        f\"{labels_df['elapsed_s'].iloc[-1]:.2f}\",\n",
    "        f\"{labels_df['elapsed_s'].iloc[-1] / 60:.2f}\",\n",
    "        f\"{1 / labels_df['dt_s'].mean():.2f}\",\n",
    "        f\"{1 / labels_df['dt_s'].median():.2f}\",\n",
    "        f\"{labels_df['timestamp'].iloc[0]:,} → {labels_df['timestamp'].iloc[-1]:,}\",\n",
    "        f\"{len(gaps)}\",\n",
    "        f\"{labels_df.isnull().sum().sum()}\",\n",
    "        f\"{labels_df['timestamp'].duplicated().sum()}\",\n",
    "        f\"{non_monotonic}\",\n",
    "        f\"{labels_df['quat_norm'].mean():.6f}\",\n",
    "        f\"{labels_df['quat_norm'].std():.6f}\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
